{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_circles\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import plot_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# importing the fashion Mnist dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import fashion_mnist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing image processing layers Conv2d,MaxPooling2D and Flatten,Droupout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Conv2D,MaxPooling2D\n",
    "from tensorflow.keras.layers import Dense,Dropout,Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes = 10\n",
    "batch_size=128\n",
    "epochs=24\n",
    "\n",
    "img_rows,img_cols = 28,28\n",
    "\n",
    "(X_train,y_train),(X_test,y_test) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 28, 28), (60000,), (10000, 28, 28), (10000,))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape,y_train.shape,X_test.shape,y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#   Deal with format issues between different backends.  Some put the # of channels in the image before the width and height of image.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "channels_last\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import backend as kb\n",
    "\n",
    "print(kb.image_data_format())\n",
    "\n",
    "if kb.image_data_format() == 'channels_first':\n",
    "    X_train = X_train.reshape(X_train.shape[0], 1, img_rows, img_cols)\n",
    "    X_test = X_test.reshape(X_test.shape[0], 1, img_rows, img_cols)\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    X_train = X_train.reshape(X_train.shape[0], img_rows, img_cols, 1)\n",
    "    X_test = X_test.reshape(X_test.shape[0], img_rows, img_cols, 1)\n",
    "    input_shape = (img_rows, img_cols, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#   Type convert and scale the test and training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 28, 28, 1), (60000,), (10000, 28, 28, 1), (10000,))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "X_train.shape,y_train.shape,X_test.shape,y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras as k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = k.utils.to_categorical(y_train, n_classes)\n",
    "y_test = k.utils.to_categorical(y_test, n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 10)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 10)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lets Create A model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_layer = Input(shape=(28,28,1),name='Input_Layer')\n",
    "\n",
    "first_cov_layer = Conv2D(filters=32,kernel_size=(3,3),activation='relu',name=\"first_convl\")(input_layer)\n",
    "\n",
    "first_max_pool = MaxPooling2D(pool_size=(2,2),name=\"first_pool\")(first_cov_layer)\n",
    "\n",
    "\n",
    "second_cov_layer = Conv2D(filters=32,kernel_size=(3,3),activation='relu',name=\"second_convl\")(first_max_pool)\n",
    "\n",
    "second_max_pool = MaxPooling2D(pool_size=(2,2),name=\"second_pool\")(second_cov_layer)\n",
    "\n",
    "flatten_layer = Flatten(name=\"flatten2Dto1D\")(second_max_pool)\n",
    "\n",
    "first_dense_layer = Dense(units=128,activation='relu',name=\"first_dense\")(flatten_layer)\n",
    "\n",
    "drop_outfrom_dense = Dropout(rate=0.5,name=\"drop_from_dense\")(first_dense_layer)\n",
    "\n",
    "ouput_layer = Dense(units=n_classes,activation='tanh',name=\"output\")(drop_outfrom_dense)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_model = Model(input_layer,ouput_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_model.compile(loss=k.losses.categorical_crossentropy,\n",
    "              optimizer=k.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Input_Layer (InputLayer)     [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "first_convl (Conv2D)         (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "first_pool (MaxPooling2D)    (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "second_convl (Conv2D)        (None, 11, 11, 32)        9248      \n",
      "_________________________________________________________________\n",
      "second_pool (MaxPooling2D)   (None, 5, 5, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten2Dto1D (Flatten)      (None, 800)               0         \n",
      "_________________________________________________________________\n",
      "first_dense (Dense)          (None, 128)               102528    \n",
      "_________________________________________________________________\n",
      "drop_from_dense (Dropout)    (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 113,386\n",
      "Trainable params: 113,386\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "conv_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 28, 28, 1), (60000, 10))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape,y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/24\n",
      "60000/60000 [==============================] - 8s 126us/sample - loss: 7.5593 - accuracy: 0.0951 - val_loss: 7.9794 - val_accuracy: 0.1014\n",
      "Epoch 2/24\n",
      "60000/60000 [==============================] - 5s 84us/sample - loss: 7.4674 - accuracy: 0.0998 - val_loss: 7.8258 - val_accuracy: 0.1016\n",
      "Epoch 3/24\n",
      "60000/60000 [==============================] - 4s 75us/sample - loss: 7.4581 - accuracy: 0.0988 - val_loss: 7.6501 - val_accuracy: 0.1014\n",
      "Epoch 4/24\n",
      "60000/60000 [==============================] - 5s 85us/sample - loss: 7.3958 - accuracy: 0.0975 - val_loss: 7.4928 - val_accuracy: 0.1017\n",
      "Epoch 5/24\n",
      "60000/60000 [==============================] - 5s 81us/sample - loss: 7.4339 - accuracy: 0.0995 - val_loss: 7.3875 - val_accuracy: 0.1015\n",
      "Epoch 6/24\n",
      "60000/60000 [==============================] - 4s 71us/sample - loss: 7.3834 - accuracy: 0.1008 - val_loss: 7.2412 - val_accuracy: 0.1015\n",
      "Epoch 7/24\n",
      "60000/60000 [==============================] - 4s 70us/sample - loss: 7.3942 - accuracy: 0.1001 - val_loss: 7.0498 - val_accuracy: 0.1015\n",
      "Epoch 8/24\n",
      "60000/60000 [==============================] - 4s 69us/sample - loss: 7.3266 - accuracy: 0.0981 - val_loss: 6.8285 - val_accuracy: 0.1017\n",
      "Epoch 9/24\n",
      "60000/60000 [==============================] - 4s 71us/sample - loss: 7.2792 - accuracy: 0.1011 - val_loss: 6.7034 - val_accuracy: 0.1017\n",
      "Epoch 10/24\n",
      "60000/60000 [==============================] - 4s 73us/sample - loss: 7.2739 - accuracy: 0.1018 - val_loss: 6.6041 - val_accuracy: 0.1018\n",
      "Epoch 11/24\n",
      "60000/60000 [==============================] - 5s 76us/sample - loss: 7.1916 - accuracy: 0.1030 - val_loss: 6.4673 - val_accuracy: 0.1019\n",
      "Epoch 12/24\n",
      "60000/60000 [==============================] - 5s 77us/sample - loss: 7.1810 - accuracy: 0.1036 - val_loss: 6.3115 - val_accuracy: 0.1018\n",
      "Epoch 13/24\n",
      "60000/60000 [==============================] - 4s 73us/sample - loss: 7.1440 - accuracy: 0.1024 - val_loss: 6.1857 - val_accuracy: 0.1017\n",
      "Epoch 14/24\n",
      "60000/60000 [==============================] - 5s 79us/sample - loss: 7.1268 - accuracy: 0.1035 - val_loss: 6.0262 - val_accuracy: 0.1018\n",
      "Epoch 15/24\n",
      "60000/60000 [==============================] - 5s 81us/sample - loss: 7.1160 - accuracy: 0.1050 - val_loss: 5.8449 - val_accuracy: 0.1020\n",
      "Epoch 16/24\n",
      "60000/60000 [==============================] - 5s 84us/sample - loss: 7.0880 - accuracy: 0.1067 - val_loss: 5.7126 - val_accuracy: 0.1016\n",
      "Epoch 17/24\n",
      "60000/60000 [==============================] - 5s 78us/sample - loss: 7.0112 - accuracy: 0.1069 - val_loss: 5.6352 - val_accuracy: 0.1016\n",
      "Epoch 18/24\n",
      "60000/60000 [==============================] - 5s 85us/sample - loss: 6.9803 - accuracy: 0.1057 - val_loss: 5.6295 - val_accuracy: 0.1017\n",
      "Epoch 19/24\n",
      "60000/60000 [==============================] - 5s 90us/sample - loss: 6.9769 - accuracy: 0.1059 - val_loss: 5.5288 - val_accuracy: 0.1017\n",
      "Epoch 20/24\n",
      "60000/60000 [==============================] - 5s 75us/sample - loss: 6.9649 - accuracy: 0.1073 - val_loss: 5.4311 - val_accuracy: 0.1016\n",
      "Epoch 21/24\n",
      "60000/60000 [==============================] - 5s 83us/sample - loss: 6.9325 - accuracy: 0.1102 - val_loss: 5.3287 - val_accuracy: 0.1019\n",
      "Epoch 22/24\n",
      "60000/60000 [==============================] - 6s 92us/sample - loss: 6.8831 - accuracy: 0.1115 - val_loss: 5.2361 - val_accuracy: 0.1022\n",
      "Epoch 23/24\n",
      "60000/60000 [==============================] - 6s 93us/sample - loss: 6.8270 - accuracy: 0.1105 - val_loss: 5.1526 - val_accuracy: 0.1023\n",
      "Epoch 24/24\n",
      "60000/60000 [==============================] - 5s 84us/sample - loss: 6.8383 - accuracy: 0.1080 - val_loss: 5.0765 - val_accuracy: 0.1025\n"
     ]
    }
   ],
   "source": [
    "hist = conv_model.fit(X_train, y_train,\n",
    "        batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(X_test, y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
